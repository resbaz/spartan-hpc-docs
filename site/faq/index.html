<!DOCTYPE html>
<head>
  <title>Spartan Documentation</title>
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <link rel="stylesheet" href="../css/theme.css">
  <link rel="stylesheet" href="https://d2h9b02ioca40d.cloudfront.net/v7.0/uom.css">
  <script src="https://d2h9b02ioca40d.cloudfront.net/v7.0/uom.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
  <script src="https://cdn.statuspage.io/se-v2.js"></script>
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
  <script src="../js/theme.js"></script>
  <script>var base_url = '..';</script>


  
  <script src="../search/require.js"></script>
  
  <script src="../search/search.js"></script>
  

  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
              (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-97236408-1', 'auto');
      ga('send', 'pageview');
  </script>

  
  
</head>

<body>

<div class="uomcontent">

  <div class="page-inner">
    <ol class="page-local-history" itemscope="" itemtype="http://schema.org/BreadcrumbList">
      <li class="root" itemprop="itemListElement" itemscope="" itemtype="http://schema.org/ListItem">
        <a href="/" title="Spartan Documentation" itemprop="item">
          <span itemprop="name">Spartan Documentation</span>
        </a>
        <meta content="1" itemprop="position" />
      </li>
      

    </ol>
    <div role="main">

      <header>

        <form action="../search.html" class="search" method="get">
          <fieldset>
            <div class="inline attached">
              <span class="fill">
                <input aria-label="Search" aria-required="true" autocomplete="off" data-error="Please enter a keyword" name="q" placeholder="Search Spartan Documentation" type="search" id="mkdocs-search-query"/>
              </span>
              <span>
              <button class="inline-button" type="submit"><span class="small icon--hide-label" data-icon="search">Go</span></button>
            </span>
            </div>
          </fieldset>
        </form>

        <div style="text-align: center; font-size: small">
            Status:
              <span class="color-dot"></span>
              <span class="color-description"></span>
            <a href="/status/"> (more...)</a>
        </div>

      </header>

      <div class="tabbed-nav" data-tabbed="" id="nav">
        <div class="full-width">
          <nav role="tablist">
            
              
              <a role="tab" href=".." >Home</a>
              
            
              
              <a role="tab" href="../getting_started/" >Getting Started</a>
              
            
              
              <a role="tab" href="../managing_data/" >Managing Data</a>
              
            
              
              <a role="tab" href="../software/" >Software</a>
              
            
              
              <a role="tab" href="../guides/" >Guides</a>
              
            
              
            
              
            
              
              <a role="tab" href="./" id="activeTab">FAQ</a>
              
            
              
            
              
            
              
            
              
            
          </nav>
        </div>
      </div>

        <p>
        
          <h2 id="whats-special-about-spartan">What's special about Spartan?</h2>
<p>Most modern HPC systems are built around a cluster of commodity computers tied together with very-fast networking. This allows computation to run across multiple cores in parallel, quickly sharing data between themselves as needed.</p>
<p>For certain jobs, this architecture is essential to achieving high-performance. For others, however, this is not the case, and each node can run without communicating with the others in the cluster. This class of problems often comes under the guise of <em><a href="https://en.wikipedia.org/wiki/Embarrassingly_parallel">embarrassingly parallel</a></em>. That is, they can be run as independent parallel tasks by splitting up the data or calculation into discrete chunks. In this case, high speed networking is unnecessary, and the resources can be better spent on utilizing more cores to achieve high performance.</p>
<p>Spartan combines both approaches. By default, jobs run in the flexible cloud partition. For those that need it, there's a physical partition running on bare-metal hardware, interconnected with low-latency 56 GigE networking.</p>
<h2 id="how-do-i-get-an-account">How do I get an account?</h2>
<p>Access to Spartan requires an an account, which you can request using <a href="https://dashboard.hpc.unimelb.edu.au/karaage">Karaage</a>. </p>
<p>Accounts are associated with a particular project; you can either join an existing project or create a new one.</p>
<p>New projects are subject to approval by the Head of Research Compute Services. Projects must demonstrate an approved research goal or goals, or demonstrate potential to support research activity. Projects require a Principle Investigator and may have additional Research Collaborators.</p>
<h2 id="how-do-i-access-spartan-once-i-have-an-account">How do I access Spartan once I have an account?</h2>
<p>You'll need an SSH client. Mac and Linux computers will already have one installed, just use the command <code>ssh yourUsername@spartan.hpc.unimelb.edu.au</code> at your terminal.</p>
<p>For Windows, you'll need to download an SSH client such as <a href="http://www.putty.org/">PuTTY</a>, set hostname as <code>spartan.hpc.unimelb.edu.au</code> and select Open. You'll be asked for your Spartan username and password.</p>
<h2 id="my-password-isnt-working">My password isn't working!</h2>
<ol>
<li>
<p>Make sure you're using your Spartan password that you set in <a href="https://dashboard.hpc.unimelb.edu.au/karaage">Karaage</a>. <strong> Your Spartan password is not necessarily the same as your central university password.</strong></p>
</li>
<li>
<p>You can request a password reset <a href="https://dashboard.hpc.unimelb.edu.au/karaage/profile/password_request/">here</a>.</p>
</li>
<li>
<p>If you are still having trouble, contact the University of Melbourne Service Desk on +61 3 8344 0999 or ext 40999 or email or <a href="mailto:service-centre@unimelb.edu.au">service-centre@unimelb.edu.au</a>.</p>
</li>
</ol>
<h2 id="how-do-i-add-people-to-a-project">How do I add people to a project?</h2>
<p>If you are a project leader you may invite people to join your project. Login to Karaage, and go to your <a href="https://dashboard.hpc.unimelb.edu.au/karaage/profile/projects/">Karaage project list</a>, select the appropriate project, and select the "Invite a new user" option. The user will then receive an invitation link to join the project and set up an account. </p>
<p><em>However</em> if the belong to an institution that does not have a SAML login process (e.g., international researchers) it is worthwhile contacting the Spartan at <a href="mailto:hpc-support@unimelb.edu.au">hpc-support@unimelb.edu.au</a>. Then the sysadmins will add the person manually to the project and reset their password.</p>
<h2 id="what-are-spartans-specifications">What are Spartan's specifications?</h2>
<p>Spartan consists of 21 bare-metal nodes with 12 cores connected via 56GigE ethernet, achieving a latency of 1.15 us.</p>
<p>The cloud partition nominally consists of 100 nodes with 8 cores each from the <a href="http://nectar.org.au/">Nectar</a> research cloud, however it is capable of accessing more as the load on Spartan grows.</p>
<p>There also exist a number of specialist nodes with expanded memory or <a href="https://en.wikipedia.org/wiki/General-purpose_computing_on_graphics_processing_units">GPGPU</a> hardware, as well as partitions dedicated to particular departments and research groups.</p>
<h2 id="what-software-is-installed">What software is installed?</h2>
<p>Spartan uses a modules system (<a href="http://lmod.readthedocs.io/en/latest/">lmod</a>) to load and unload different packages, including different versions of the same software. You can check what's currently installed using the <code>module avail</code> command, and load a module with the <code>module load</code> command.</p>
<p>Typically one doesn't load modules directly unless they're in an interactive session on a compute node (launched with <code>sinteractive</code>). Instead you load the modules in your Slurm script before executing your particular software.</p>
<h2 id="what-if-the-software-i-need-is-not-installed">What if the software I need is not installed?</h2>
<p><a href="mailto:hpc-support@unimelb.edu.au">Get in contact</a> with us and we can install it for you. Generally speaking, you should avoid compiling software on Spartan, unless you wrote it from scratch for your own use. By letting us handle it, we can make sure that:</p>
<ul>
<li>It works</li>
<li>Software licenses are managed</li>
<li>Code is compiled with the appropriate flags to maximize performance</li>
<li>Others users can also make use of the software.</li>
</ul>
<h2 id="where-do-i-go-for-help">Where do I go for help?</h2>
<p>First off, we encourage researchers that are new to HPC to undertake training with us. It's free! And we can tailor a specific training program for you, for instance around a specific software package, if there is the demand. Check <a href="http://melbourne.resbaz.edu.au/calendar">here</a> for a calendar of when the next event is planned, along with the other training programs offered in coordination with ResBaz. Sign up to be notified of our next training events at: <a href="http://melbourne.resbaz.edu.au/participate">http://melbourne.resbaz.edu.au/participate</a></p>
<p>Second, check the documentation here, as well as for the software you're running on Spartan (like Slurm).</p>
<p>Finally, if you ever get stuck, please feel free to <a href="mailto:hpc-support@unimelb.edu.au">email HPC support</a>. We're here to help make your research more productive and enjoyable, and we'll do everything we can to help. </p>
<h2 id="how-do-i-get-access-to-gpus">How do I get access to GPUs?</h2>
<p>Spartan includes two partitions with GPUs (as well as a third private <code>physics-gpu</code> partition). </p>
<p>The legacy <code>gpu</code> partition includes four Nvidia K80 GPUs per node, while the newer <code>gpgpu</code> partition includes four Nvidia P100 GPUs per node. </p>
<p>They can be specified in your job script with <code>#SBATCH --partition gpu</code> and <code>#SBATCH --partition gpgpu</code>, respectively.</p>
<p>You'll also need to include a generic resource request in your job script, for example <code>#SBATCH --gres=gpu:2</code> will request two GPUs for your job.</p>
<p>A range of GPU-accelerated software such as TensorFlow is available on Spartan <a href="https://github.com/resbaz/spartan-examples/tree/master/TensorFlow">example</a>, as well as CUDA for developing your own GPU applications <a href="https://github.com/resbaz/spartan-examples/tree/master/GPU">example</a>.</p>
<p><strong>N.B. The GPGPU partition is not automatically available to all Spartan users, and a dedicated project must be created to request access. See <a href="../gpu/">here</a> for more details.</strong></p>
<h2 id="how-do-i-submit-a-job">How do I submit a job?</h2>
<p>You'll need your data files and scripts, the software you want to run installed on Spartan, and a job script so that Spartan knows how to put everything together. Check out <a href="../getting_started/">Getting Started</a> for an example.</p>
<h2 id="do-i-need-to-know-how-to-use-linux">Do I need to know how to use Linux?</h2>
<p>Just the basics to get started. We cover this in our introductory training course, and there are many online resources available to get you started, such as <a href="http://www.ee.surrey.ac.uk/Teaching/Unix/">this tutorial</a>. </p>
<h2 id="how-do-i-create-a-multi-core-job">How do I create a multi-core job?</h2>
<p>There are two options here. If you want to run a single instance of your program and have that program access 8 cores, you can do this:</p>
<pre><code>#SBATCH --ntasks=1
#SBATCH --cpus-per-task=8
</code></pre>

<p>This is the typical approach if your program makes use of multi-threading or subprocesses to make use of the additional cores.</p>
<p>Alternatively, if you'd like to run multiple instances (tasks) of your program, each on their own core:</p>
<pre><code>#SBATCH --nodes=1
#SBATCH --ntasks=8
#SBATCH --cpus-per-task=1
</code></pre>

<p>This approach might be used for jobs where there are multiple instances of a program running at once, but they communicate with each other (e.g. using OpenMPI) and so should be kept within a single node so that communication between tasks is quick.</p>
<p>Keep in mind the number of cores that actually exist within a node, eight for the cloud partition and twelve for physical -- you can't request more than this.</p>
<h2 id="how-do-i-create-a-multi-node-job">How do I create a multi-node job?</h2>
<p>Here's an example of a job with two nodes, each using 12 cores.</p>
<pre><code>#SBATCH --nodes=2
#SBATCH --ntasks=2
#SBATCH --cpus-per-task=12
</code></pre>

<p>Note that you can't have a single instance of a program running across different nodes. Instead, you would usually run two instances of a program (one on each node), and have them pass messages between each other so they can work in parallel using a framework like OpenMPI.</p>
<p>For multi-node jobs, it is usually preferable to use the physical partition, because this partition has faster networking between nodes. </p>
<h2 id="what-other-options-are-there-for-running-my-job">What other options are there for running my job?</h2>
<p>Many different permutations of cores, memory, nodes, tasks and dependencies are possible to suit different use cases. Refer to the documentation for <a href="https://slurm.schedmd.com/">Slurm</a> (the job manager we use on Spartan) for details.</p>
<h2 id="how-do-i-create-a-job-array">How do I create a job array?</h2>
<p>Job arrays are great for kicking off a large number of independent jobs at once. For instance, if you're batch processing a series of files, and the processing for each file can be performed independently of any other.</p>
<p>Say we have an array of files, <code>data_1.dat</code> to <code>data_50.dat</code> to process with <code>myProgram</code>:</p>
<pre><code>#!/bin/bash
#SBATCH --ntasks=1
#SBATCH --time=0-00:15:00
#SBATCH --array=1-50

myProgram data_${SLURM_ARRAY_TASK_ID}.dat
</code></pre>

<p>This will create 50 jobs, each calling <code>myProgram</code> with a different data file. These jobs will run in any order, as soon as resources are available (potentially, all at the same time!)</p>
<h2 id="how-do-i-request-more-memory">How do I request more memory?</h2>
<p>By default the scheduler will set memory equal to the total amount on a compute node divided by the number of cores requested. In some cases this might not be enough (e.g., very large dataset that needs to be loaded with low level of parallelisation).</p>
<p>Additional memory can be allocated with the <code>--mem=[mem][M|G|T]</code> directive (entire job) or <code>--mem-per-cpu=[mem][M|G|T]</code> (per core). Maximum should be based around total cores -1 (for system processes). The --mem-per-cpu directive is for threads for OpenMP applications and processor ranks for MPI.</p>
<p>It is best to reserve some memory (about 1 core's worth) for system processes.</p>
<h2 id="are-there-more-examples-i-can-look-at">Are there more examples I can look at?</h2>
<p>If you go to <code>/usr/local/common/</code> on Spartan there are examples for a wide range of programs. You can copy these into your home directory and run them for yourself.</p>
<h2 id="how-do-i-make-my-program-run-fast-on-spartan">How do I make my program run fast on Spartan?</h2>
<p>Spartan, like almost all modern HPC systems, delivers high-performance by combining lots of smaller computers (nodes) together in a cluster. Each core within a node probably isn't much faster than on your own personal computer, so improved performance is dependent on using parallel processing (MPI or OpenMP) or job arrays. </p>
<h2 id="how-do-i-cite-spartan-in-my-publications">How do I cite Spartan in my publications?</h2>
<p>If you use Spartan to obtain results, we'd very much appreciate if you'd cite our service, including the DOI below. This makes it easy for us demonstrate research impact, helping to secure ongoing funding for expansion and user support.</p>
<p><code>Lev Lafayette, Greg Sauter, Linh Vu, Bernard Meade, "Spartan Performance and Flexibility: An HPC-Cloud Chimera", OpenStack Summit, Barcelona, October 27, 2016. doi.org/10.4225/49/58ead90dceaaa</code></p>
<h2 id="how-do-i-transition-my-work-from-the-old-hpc-system-edward-to-spartan">How do I transition my work from the old HPC system Edward to Spartan?</h2>
<p>Here's a <a href="../edward_transition/">guide</a> to help you.</p>
<h2 id="how-do-setup-passwordless-ssh-login">How do setup passwordless SSH login?</h2>
<p>A passwordless SSH for Spartan will make your life easier. You won't
even need to remember your password!</p>
<p>If you have a *nix system (e.g., UNIX, Linux, MacOS X) open up a
terminal on your <em>local</em> system and generate a keypair.</p>
<pre><code>$ ssh-keygen -t rsa
Generating public/private rsa key pair.
Enter file in which to save the key (/home/user/.ssh/id_rsa): 
Created directory '/home/user/.ssh'.
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/user/.ssh/id_rsa.
Your public key has been saved in /home/user/.ssh/id_rsa.pub.
The key fingerprint is:
43:51:43:a1:b5:fc:8b:b7:0a:3a:a9:b1:0f:66:73:a8 user@localhost
</code></pre>

<p>Now append the new public key to <code>~/.ssh/authorized_keys</code> on Spartan (you'll be asked for your password one last time).</p>
<pre><code>$ cat .ssh/id_rsa.pub | ssh username@spartan.hpc.unimelb.edu.au 'cat &gt;&gt; .ssh/authorized_keys'
</code></pre>

<p>Depending on your version of SSH you might also have to do the following
changes:</p>
<ul>
<li>Put the public key in .ssh/authorized_keys2</li>
<li>Change the permissions of .ssh to 700</li>
<li>Change the permissions of .ssh/authorized_keys2 to 640</li>
</ul>
<p>You can now SSH to Spartan without having to enter your password!</p>
<h2 id="how-can-i-avoid-typing-myusernamespartanhpcunimelbeduau-everytime-i-connect">How can I avoid typing myUsername@spartan.hpc.unimelb.edu.au everytime I connect?</h2>
<p>An SSH config file will also make your life easier. It allows you to create alises (i.e. shortcuts) for a given hostname. </p>
<p>Create the text file in your <code>~/.ssh</code> directory with your preferred text editor, for example, <code>nano</code>.</p>
<pre><code>nano .ssh/config
</code></pre>

<p>Enter the following (replacing <code>username</code> with your actual username of course!):</p>
<pre><code>Host *
ServerAliveInterval 120
Host spartan
       Hostname spartan.hpc.unimelb.edu.au
       User username
</code></pre>

<p>Now to connect to Spartan, you need only type <code>ssh spartan</code>.</p>
<h2 id="can-i-run-interactive-gui-applications-on-spartan">Can I run interactive GUI applications on Spartan?</h2>
<p>Yes. HPC systems are optimised for command line batch processing, but some workflows and software packages benefit from access to a graphical user interface (GUI). One option is to use <a href="../guides/desktop/">Strudel</a>, which provides a desktop-like experience, and the other is to use X forwarding, which allows your application to display directly on your own machine.</p>
<p>Here's an example:</p>
<ol>
<li>Install X Windows on your machine. This is built-in for Linux, available via <a href="https://www.xquartz.org">XQuartz</a> for OS X, and <a href="https://mobaxterm.mobatek.net/">MobaXterm</a> for Windows.</li>
<li>SSH into Spartan using the -Y flag, e.g. <code>ssh -Y username@spartan.hpc.unimelb.edu.au</code></li>
<li>Open an interactive session on a compute node using the --x11 flag, i.e. <code>sinteractive --x11</code>. You can set the partition, wall time and core count as usual for the <code>sinteractive</code> command.</li>
<li>Start your GUI application within the interactive session, which will then be forwarded to your local machine. For example, to start MATLAB:</li>
</ol>
<pre><code>$ module load MATLAB
$ matlab
</code></pre>
        
        </p>


      <!--UoM CSS handles local nav for us instead of mkdocs-->
      <div class="jumpnav"></div>

    </div>

  </div>
</body>

<script>

  $(document).ready(function(){
      // Force tab link markers/highlighting to shift for external links (not supported out of the box).
      $('a').removeAttr('data-current');
      $('#activeTab').attr({'data-current': ''});
  });

</script>


<script>
  var sp = new StatusPage.page({ page: 'zxld2sws8c9x'});

  sp.summary({
    success: function(data) {
      // adds the text description to the dropdown
      $('.color-description').text(data.status.description);
      // appends the status indicator as a class name so we can use the right color for the status light thing
      $('.color-dot').addClass(data.status.indicator);
    }
  });
</script>
</html>